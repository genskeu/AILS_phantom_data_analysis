{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def read_results(csv_path):\n",
    "    df = pd.read_csv(csv_path)\n",
    "    tissue = os.path.basename(csv_path).split('_')[1].split('.')[0]\n",
    "    df['tissue'] = tissue\n",
    "    network_rep = os.path.basename(csv_path.split('/')[-3]) if csv_path.split('/')[-2].startswith('dose') else os.path.basename(csv_path.split('/')[-2]) \n",
    "    network_rep = network_rep.split('_')\n",
    "    df['network'] = \"_\".join(network_rep[:-2])\n",
    "    if \"_\".join(network_rep[:-2]) == '3dres_fullres_LiTS_151':\n",
    "        print(csv_path)\n",
    "    df['rep'] = network_rep[-1]\n",
    "    df['tta'] = 'tta' == network_rep[-4]\n",
    "\n",
    "    date_phantom_ct =  os.path.basename(csv_path.split('/')[-5]) if csv_path.split('/')[-2].startswith('dose') else os.path.basename(csv_path.split('/')[-4]) \n",
    "    date_phantom_ct = date_phantom_ct.split('_')\n",
    "    df['phantom'] = date_phantom_ct[1].replace('phantom', '')\n",
    "    df['ct'] = date_phantom_ct[3]\n",
    "    df['date'] = date_phantom_ct[0]\n",
    "\n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import os \n",
    "\n",
    "# def combine_photon_results(results_folder, type):\n",
    "#     results = []\n",
    "#     for root, dirs, files in os.walk(results_folder):\n",
    "#         for file in files:\n",
    "#             if file.startswith(type):\n",
    "#                 df_temp = pd.read_csv(os.path.join(root, file))\n",
    "#                 results.append(df_temp)\n",
    "    \n",
    "#     results_df = pd.concat(results)\n",
    "#     results_df = results_df.to_csv(f'{results_folder}/{type[0:-1]}.csv', index=False)\n",
    "\n",
    "# combine_photon_results(\"/home/uli/data/Insync/uligenske@gmail.com/Google Drive/arbeit/deep_learning/segmentation/datasets/phantom_datasets/230915_phantom241_043/results/outout_241_photon/output_241_photon_2d_tta_enabled_rep1\", \n",
    "#                        \"results_lesions_\")\n",
    "\n",
    "\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read results\n",
    "\n",
    "path_all_phantom_data = '/home/uli/data/Insync/uligenske@gmail.com/Google Drive/arbeit/deep_learning/segmentation/datasets/phantom_datasets'\n",
    "all_phantom_dirs = os.listdir(path_all_phantom_data)\n",
    "all_phantom_dirs = [d for d in all_phantom_dirs if os.path.isdir(os.path.join(path_all_phantom_data, d)) and len(d.split('_')) >= 4]\n",
    "phantom_dirs_241_247 = [d for d in all_phantom_dirs if d.split('_')[1].endswith('241') or d.split('_')[1].endswith('247')]\n",
    "phantom_dirs_241_247_path = [os.path.join(path_all_phantom_data, d) for d in phantom_dirs_241_247 ]\n",
    "df = pd.DataFrame()\n",
    "for path in phantom_dirs_241_247_path:\n",
    "    for root, dirs, files in os.walk(path):\n",
    "        for file in files:\n",
    "            if file in ['results_lesion.csv', 'results_lesions.csv', 'results_liver.csv']:\n",
    "                csv_path = os.path.join(root, file)\n",
    "                df_temp = read_results(csv_path)\n",
    "                df = pd.concat([df, df_temp])\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['250618', '250727', '240306', '250515', '230915', '250604',\n",
       "       '250321', '250404', '250411', '231205', '250322', '250328'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"date\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add analysis meta information\n",
    "df_non_photon = df[df[\"ct\"].isin([\"GE\", \"CT4\"])].copy()\n",
    "df_non_photon.loc[:,'dose'] = df_non_photon['analysis_name'].apply(lambda x: x.split('_')[2])\n",
    "df_non_photon.loc[:,'kernel'] = df_non_photon['analysis_name'].apply(lambda x: x.split('_')[3])\n",
    "df_non_photon.loc[:,'reco'] = df_non_photon['analysis_name'].apply(lambda x: x.split('_')[4])\n",
    "df_non_photon.loc[:,'rev_time'] = df_non_photon[\"analysis_name\"].apply(lambda x: x.split(\"_\")[6] if len(x.split(\"_\")) in [7,12,13] else None)\n",
    "\n",
    "df_photon = df[df[\"ct\"] == \"photon\"]\n",
    "df_photon.loc[:,'dose'] = df_photon['analysis_name'].apply(lambda x: x.split('_')[2])\n",
    "df_photon.loc[:,'CTDIvol'] = df_photon['analysis_name'].apply(lambda x: x.split('_')[-3])\n",
    "df_photon.loc[:,'reco'] = df_photon['analysis_name'].apply(lambda x: x.split('_')[-2])\n",
    "df_photon.loc[:,'kernel'] = df_photon['analysis_name'].apply(lambda x: x.split('_')[-1])\n",
    "df_photon.loc[:,'slice_thickness'] = df_photon['analysis_name'].apply(lambda x: x.split('_')[-1])\n",
    "df_photon.loc[:,'rev_time'] = df_photon[\"analysis_name\"].apply(lambda x: x.split(\"_\")[3])\n",
    "\n",
    "df = pd.concat([df_photon, df_non_photon])\n",
    "df = df.reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some predictions are from empty volumes\n",
    "# remove them, they can be identified via the size of the masks (49kb)\n",
    "mask_path = \"../../231205_phantom247_055_CT4/results/3d_fullres_LiTS+phantom_254_repetition_4\"\n",
    "masks = os.listdir(mask_path)\n",
    "masks = [mask for mask in masks if os.path.getsize(os.path.join(mask_path, mask)) < 50000 and mask.endswith('.nii.gz')]\n",
    "if len(masks) == 0:\n",
    "    print(\"Warning: no masks to remove found!\")\n",
    "analysis_names_to_remove = [mask[:-7] for mask in masks]\n",
    "df = df[~df['analysis_name'].isin(analysis_names_to_remove)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#size filter for predictions, ignore predictions smaller than this volume\n",
    "df['volume_pred'] = df.apply(lambda x: x['px_numb_pred']*0.586*0.586*0.8 if x['ct'] == 'canon' else x['px_numb_pred']*0.586*0.586*0.625, axis=1)\n",
    "df['volume_gt'] = df.apply(lambda x: x['px_numb_gt']*0.586*0.586*0.8 if x['ct'] == 'canon' else x['px_numb_gt']*0.586*0.586*0.625, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/2906632 [05:34<270168:25:15, 334.62s/it]\n",
      "100%|█████████▉| 2905976/2906632 [04:26<00:00, 7599.99it/s] "
     ]
    }
   ],
   "source": [
    "import tqdm\n",
    "# add CTDIvol values\n",
    "import pandas as pd\n",
    "base_path = \"/home/uli/data/Insync/uligenske@gmail.com/Google Drive/arbeit/deep_learning/segmentation/datasets/phantom_datasets\"\n",
    "pbar = tqdm.tqdm(total=len(df))\n",
    "df_CDTI_CT4 = pd.read_csv('meta/dicom_dose_data_mA_CTDIvol_CT4.csv')\n",
    "df_CDTI_GE = pd.read_csv('meta/dicom_dose_data_mA_CTDIvol_GE.csv')\n",
    "df[\"dose\"] = df[\"dose\"].astype(int)\n",
    "df[\"rev_time\"] = df[\"rev_time\"].astype(float)\n",
    "\n",
    "phantom = df[\"phantom\"].values\n",
    "ct = df[\"ct\"].values\n",
    "dose = df[\"dose\"].values\n",
    "rev_time = df[\"rev_time\"].values\n",
    "cdti_vol = []\n",
    "for index in range(len(df)):\n",
    "    pbar.update(1)\n",
    "    # for CT match by tubecurrent and for GE match by tubecurrent and revolution time\n",
    "    if phantom[index] in [\"241\",\"247\"] and ct[index] == \"CT4\":\n",
    "        dose_CTDIvols = df_CDTI_CT4[\"CTDIvol\"][df_CDTI_CT4[\"mA\"] == dose[index]].values\n",
    "    elif phantom[index] in [\"241\",\"247\"] and ct[index] == \"GE\":\n",
    "        dose_CTDIvols = df_CDTI_GE[\"CTDIvol\"][(df_CDTI_GE[\"mA\"] == dose[index]) & (df_CDTI_GE[\"RevolutionTime\"] == rev_time[index])].values\n",
    "    else:\n",
    "        cdti_vol.append(df[\"CTDIvol\"][index])\n",
    "        continue\n",
    "    \n",
    "    if len(dose_CTDIvols) > 1:\n",
    "        raise ValueError(\"more than one dose found\")\n",
    "    elif len(dose_CTDIvols) == 0:\n",
    "        raise ValueError(\"no dose found\")\n",
    "\n",
    "    cdti_vol.append(dose_CTDIvols[0])\n",
    "\n",
    "df[\"CTDIvol\"] = cdti_vol\n",
    "df[\"manufacturer\"] = df[\"ct\"].apply(lambda x: \"ge\" if x == \"GE\" else \"canon\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rev_time[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_liver = df[df['tissue'] == 'liver']\n",
    "df_liver.to_csv('results_csv/results_liver_paper.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['3d_fullres_LiTS_151_res', '3d_fullres_LiTS_151',\n",
       "       '3d_fullres_LiTS+phantom_254_res', '3d_fullres_LiTS+phantom_255',\n",
       "       '3d_fullres_LiTS+phantom_256', '3d_fullres_LiTS+phantom_257_res',\n",
       "       '3d_fullres_LiTS+phantom_247_res', '3d_fullres_LiTS+phantom_247',\n",
       "       '3d_fullres_LiTS+phantom_250_res',\n",
       "       '3d_fullres_LiTS+metaphantom20-100mA_252_tta_enabled',\n",
       "       '3d_fullres_LiTS+phantom_257', '3d_fullres_tta_enabled',\n",
       "       '3d_fullres_LiTS+phantom_254', '2d_tta_enabled',\n",
       "       '2d_LiTS+phantom_254', '3d_fullres_LiTS+phantom_250',\n",
       "       '3d_fullres_LiTS+phantom_259', '3d_fullres_LiTS+phantom_258',\n",
       "       '3d_fullres_LiTS+phantom_249', '3d_fullres_LiTS+phantom_246'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_liver[\"network\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lesions = df[df['tissue'] == 'lesions']\n",
    "df_lesions.to_csv('results_csv/results_lesions_paper.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lesion = df[df['tissue'] == 'lesion'].copy()\n",
    "df_lesion.loc[:,\"lesion_id\"] = df_lesion[\"filename_gt\"].apply(lambda x: str(x).split('_')[0])\n",
    "df_lesion.loc[:,\"filename_gt\"] = df_lesion['filename_gt'].str.split('~')\n",
    "df_lesion = df_lesion.explode(\"filename_gt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = \"/home/uli/data/Insync/uligenske@gmail.com/Google Drive/arbeit/deep_learning/segmentation/datasets/phantom_datasets\"\n",
    "df_meta = pd.DataFrame()\n",
    "# add metadata\n",
    "paths_metainfo_phantoms = {\n",
    "#    '238': ['../phantom_datasets/230912_phantom238_055_unzipped_archive/meta/config/spheres.xlsx', \"Version 3 (finale)\"],\n",
    "    241: [os.path.join(base_path,'230915_phantom241_043_CT4/meta/config/spheres.xlsx'), \"Version 3 (finale)\"],\n",
    "    247: [os.path.join(base_path,'231205_phantom247_055_CT4/meta/config/spheres.xlsx'), \"Version 3 (finale)\"],\n",
    "#    '248': ['../phantom_datasets/230915_phantom241_043_unzipped_archive/meta/config/spheres.xlsx', \"Version 3 final design\"],\n",
    "#    'semi': ['../phantom_datasets/230401_semiantro_unzipped_archive/meta/design_vorlage/spheres.xlsx', \"1080_8-8-8-12-12-8-8\"],\n",
    "#    '043old': ['../phantom_datasets/230915_phantom241_043_unzipped_archive/meta/config/spheres.xlsx', \"Version 3 final design\"]\n",
    "}\n",
    "for phantom in paths_metainfo_phantoms.keys():\n",
    "    meta_infos = pd.read_excel(paths_metainfo_phantoms[phantom][0], sheet_name=paths_metainfo_phantoms[phantom][1])\n",
    "    meta_infos['phantom'] = str(phantom)\n",
    "    meta_infos['lesion_id'] = meta_infos['name']\n",
    "    df_meta = pd.concat([df_meta, meta_infos])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lesion_meta = df_lesion.merge(df_meta, on=['lesion_id', 'phantom'], how='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2906632/2906632 [04:42<00:00, 7599.99it/s]"
     ]
    }
   ],
   "source": [
    "df_lesion_meta.to_csv('results_csv/results_lesion_paper.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['3d_fullres_LiTS_151_res', '3d_fullres_LiTS_151',\n",
       "       '3d_fullres_LiTS+phantom_254_res', '3d_fullres_LiTS+phantom_249',\n",
       "       '3d_fullres_LiTS+phantom_255', '3d_fullres_LiTS+phantom_256',\n",
       "       '3d_fullres_LiTS+phantom_257_res',\n",
       "       '3d_fullres_LiTS+phantom_247_res', '3d_fullres_LiTS+phantom_247',\n",
       "       '3d_fullres_LiTS+phantom_250_res', '3d_fullres_LiTS+phantom_246',\n",
       "       '3d_fullres_LiTS+metaphantom20-100mA_252_tta_enabled',\n",
       "       '3d_fullres_LiTS+phantom_257', '3d_fullres_tta_enabled',\n",
       "       '3d_fullres_LiTS+phantom_254', '3d_fullres_LiTS+phantom_250',\n",
       "       '3d_fullres_LiTS+phantom_259', '3d_fullres_LiTS+phantom_258',\n",
       "       '2d_tta_enabled', '2d_LiTS+phantom_254'], dtype=object)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_lesion_meta[\"network\"].unique()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "val_tool",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
